import yfinance as yf
from datetime import datetime, timedelta
import pytz
import psycopg2
from src.alphasignal.config import settings
from src.alphasignal.core.logger import logger
from src.alphasignal.core.database import IntelligenceDB

class BacktestEngine:
    def __init__(self, db: IntelligenceDB):
        self.db = db
        self.current_position = None # Initial state: No position (None)

    def process_signal(self, signal_direction: str) -> bool:
        """
        å¤„ç†äº¤æ˜“ä¿¡å·å¹¶åº”ç”¨æ—¥å†…åŒå‘å»é‡é€»è¾‘ã€‚
        Args:
            signal_direction (str): æ–°çš„ä¿¡å·æ–¹å‘ï¼Œ'Long' æˆ– 'Short'ã€‚
        Returns:
            bool: å¦‚æœæ ¹æ®å»é‡è§„åˆ™å¼€ä»“æˆ–åè½¬ä»“ä½ï¼Œåˆ™è¿”å› Trueï¼›å¦åˆ™è¿”å› False (ä¿¡å·è¢«è·³è¿‡)ã€‚
        """
        if signal_direction not in ['Long', 'Short']:
            logger.warning(f"æœªçŸ¥ä¿¡å·æ–¹å‘: {signal_direction}ï¼Œè·³è¿‡å¤„ç†ã€‚")
            return False

        trade_initiated = False

        if signal_direction == 'Long':
            if self.current_position in [None, 'Short']:
                logger.info(f"â¡ï¸ æ–°ä¿¡å·: Long. å½“å‰æŒä»“: {self.current_position}. å¼€å¤šä»“ã€‚")
                self.current_position = 'Long'
                trade_initiated = True
            elif self.current_position == 'Long':
                logger.info("ğŸš« æ–°ä¿¡å·: Long. å½“å‰æŒä»“: Long. åŒå‘ä¿¡å·ï¼Œè·³è¿‡ã€‚")
                trade_initiated = False
        elif signal_direction == 'Short':
            if self.current_position in [None, 'Long']:
                logger.info(f"â¡ï¸ æ–°ä¿¡å·: Short. å½“å‰æŒä»“: {self.current_position}. å¼€ç©ºä»“ã€‚")
                self.current_position = 'Short'
                trade_initiated = True
            elif self.current_position == 'Short':
                logger.info("ğŸš« æ–°ä¿¡å·: Short. å½“å‰æŒä»“: Short. åŒå‘ä¿¡å·ï¼Œè·³è¿‡ã€‚")
                trade_initiated = False
        
        return trade_initiated

    def sync_outcomes(self):
        """
        [è‡ªåŠ¨å›å¡«] æ£€æŸ¥æ—§æ•°æ®å¹¶æ›´æ–° T+1h, T+24h çš„ä»·æ ¼
        é‡‡ç”¨ "Next Trading Candle" é€»è¾‘ï¼Œç¡®ä¿å¯¹é½äº¤æ˜“æ—¶æ®µã€‚
        """
        pending_records = self.db.get_pending_outcomes()
        if not pending_records:
            return

        logger.info(f"â³ æ­£åœ¨åŒæ­¥ {len(pending_records)} æ¡å†å²æ•°æ®çš„æ”¶ç›Šç‡...")

        # 1. ç¡®å®šæ‰€éœ€çš„å†å²æ•°æ®èŒƒå›´
        min_time = None
        max_time = None
        
        parsed_records = []

        for record in pending_records:
            try:
                raw_time = record['timestamp']
                # ç»Ÿä¸€è½¬ä¸º UTC datetime
                if isinstance(raw_time, str):
                    try:
                        dt = datetime.strptime(raw_time, "%Y-%m-%d %H:%M:%S")
                    except ValueError:
                        dt = datetime.strptime(raw_time, "%Y-%m-%d %H:%M:%S.%f%z")
                else:
                    dt = raw_time
                
                if dt.tzinfo is None:
                    dt = pytz.utc.localize(dt)
                else:
                    dt = dt.astimezone(pytz.utc)
                
                parsed_records.append((record, dt))

                if min_time is None or dt < min_time:
                    min_time = dt
                if max_time is None or dt > max_time:
                    max_time = dt
            except Exception as e:
                logger.warning(f"è·³è¿‡æ—¶é—´æ ¼å¼é”™è¯¯çš„è®°å½• ID {record.get('id')}: {e}")

        if not parsed_records:
            return

        # 2. è·å–å†å²æ•°æ® (åŠ¨æ€èŒƒå›´ + 7å¤©ç¼“å†²)
        fetch_start = (min_time - timedelta(days=7)).strftime('%Y-%m-%d')
        fetch_end = (max_time + timedelta(days=7)).strftime('%Y-%m-%d')
        
        logger.info(f"ğŸ“ˆ è·å–è¡Œæƒ…æ•°æ®èŒƒå›´: {fetch_start} è‡³ {fetch_end}")
        
        try:
            ticker = yf.Ticker("GC=F")
            # ä¼˜å…ˆå°è¯•è·å–è¾ƒé•¿å†å²
            hist = ticker.history(start=fetch_start, end=fetch_end, interval="1h")
            
            if hist.empty:
                logger.warning("æœªèƒ½è·å–åˆ°è¡Œæƒ…æ•°æ®ï¼Œè·³è¿‡æœ¬æ¬¡åŒæ­¥")
                return

            # ç»Ÿä¸€æ—¶åŒºä¸º UTC
            if hist.index.tz is None:
                hist.index = hist.index.tz_localize('UTC')
            else:
                hist.index = hist.index.tz_convert('UTC')
                
        except Exception as e:
            logger.warning(f"è·å–å†å²è¡Œæƒ…å¤±è´¥: {e}")
            return

        # 3. é€æ¡åŒ¹é… (Next Trading Candle)
        success_count = 0
        for record, record_time in parsed_records:
            try:
                # å®šä¹‰è¦åŒæ­¥çš„çª—å£å’Œå¯¹åº”çš„ timedelta
                windows = {
                    'price_15m': timedelta(minutes=15),
                    'price_1h': timedelta(hours=1),
                    'price_4h': timedelta(hours=4),
                    'price_12h': timedelta(hours=12),
                    'price_24h': timedelta(hours=24)
                }
                
                outcomes = {}
                for col, delta in windows.items():
                    target_time = record_time + delta
                    idx = hist.index.searchsorted(target_time)
                    
                    if idx < len(hist):
                        matched_time = hist.index[idx]
                        # å…è®¸ 4 å¤©çš„ gap (è¦†ç›–é•¿å‘¨æœ«)
                        if (matched_time - target_time).total_seconds() <= 4 * 86400:
                            outcomes[col] = round(float(hist.iloc[idx]['Close']), 2)

                if outcomes:
                    self.db.update_outcome(record['id'], **outcomes)
                    success_count += 1
                
            except Exception as e:
                logger.warning(f"å•æ¡å›å¡«å¤±è´¥ ID {record['id']}: {e}")
        
        logger.info(f"âœ… åŒæ­¥å®Œæˆ: æˆåŠŸå›å¡« {success_count}/{len(pending_records)} æ¡")

    def get_confidence_stats(self, keyword):
        """
        [ç­–ç•¥æ‰§è¡Œ] æ ¹æ®å…³é”®è¯æŸ¥è¯¢å†å²è¡¨ç°
        Returns:
            dict: {
                "count": 12,
                "win_rate": 0.75, # 75% æ¦‚ç‡ä¸Šæ¶¨
                "avg_return": 0.42 # å¹³å‡æ¶¨å¹… %
            }
        """
        # ä½¿ç”¨ PostgreSQL è¿æ¥
        try:
            with psycopg2.connect(
                host=settings.POSTGRES_HOST,
                port=settings.POSTGRES_PORT,
                user=settings.POSTGRES_USER,
                password=settings.POSTGRES_PASSWORD,
                dbname=settings.POSTGRES_DB
            ) as conn:
                with conn.cursor() as cursor:
                    query = """
                        SELECT gold_price_snapshot, price_1h 
                        FROM intelligence 
                        WHERE (content ILIKE %s OR summary::text ILIKE %s) 
                        AND price_1h IS NOT NULL
                    """
                    pattern = f"%{keyword}%"
                    cursor.execute(query, (pattern, pattern))
                    rows = cursor.fetchall()

            if not rows:
                return None

            total = len(rows)
            up_count = 0
            total_return = 0

            for start_price, end_price in rows:
                if not start_price or not end_price:
                    continue
                
                ret = (end_price - start_price) / start_price * 100
                total_return += ret
                if ret > 0:
                    up_count += 1
            
            if total == 0:
                return None

            return {
                "count": total,
                "win_rate": round(up_count / total * 100, 1),
                "avg_return": round(total_return / total, 2)
            }
        except Exception as e:
            logger.error(f"Error calculating confidence stats: {e}")
            return None
