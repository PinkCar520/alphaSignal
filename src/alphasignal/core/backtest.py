import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
import pytz
import psycopg2
from src.alphasignal.config import settings
from src.alphasignal.core.logger import logger
from src.alphasignal.core.database import IntelligenceDB

class BacktestEngine:
    def __init__(self, db: IntelligenceDB):
        self.db = db
        self.current_position = None # Initial state: No position (None)
        self.last_sync_attempt = datetime.min.replace(tzinfo=pytz.utc)
        self.sync_cooldown_minutes = 15 # Initial cooldown

    def process_signal(self, signal_direction: str) -> bool:
        """
        å¤„ç†äº¤æ˜“ä¿¡å·å¹¶åº”ç”¨æ—¥å†…åŒå‘å»é‡é€»è¾‘ã€‚
        Args:
            signal_direction (str): æ–°çš„ä¿¡å·æ–¹å‘ï¼Œ'Long' æˆ– 'Short'ã€‚
        Returns:
            bool: å¦‚æœæ ¹æ®å»é‡è§„åˆ™å¼€ä»“æˆ–åè½¬ä»“ä½ï¼Œåˆ™è¿”å› Trueï¼›å¦åˆ™è¿”å› False (ä¿¡å·è¢«è·³è¿‡)ã€‚
        """
        if signal_direction not in ['Long', 'Short']:
            logger.warning(f"æœªçŸ¥ä¿¡å·æ–¹å‘: {signal_direction}ï¼Œè·³è¿‡å¤„ç†ã€‚")
            return False

        trade_initiated = False

        if signal_direction == 'Long':
            if self.current_position in [None, 'Short']:
                logger.info(f"â¡ï¸ æ–°ä¿¡å·: Long. å½“å‰æŒä»“: {self.current_position}. å¼€å¤šä»“ã€‚")
                self.current_position = 'Long'
                trade_initiated = True
            elif self.current_position == 'Long':
                logger.info("ğŸš« æ–°ä¿¡å·: Long. å½“å‰æŒä»“: Long. åŒå‘ä¿¡å·ï¼Œè·³è¿‡ã€‚")
                trade_initiated = False
        elif signal_direction == 'Short':
            if self.current_position in [None, 'Long']:
                logger.info(f"â¡ï¸ æ–°ä¿¡å·: Short. å½“å‰æŒä»“: {self.current_position}. å¼€ç©ºä»“ã€‚")
                self.current_position = 'Short'
                trade_initiated = True
            elif self.current_position == 'Short':
                logger.info("ğŸš« æ–°ä¿¡å·: Short. å½“å‰æŒä»“: Short. åŒå‘ä¿¡å·ï¼Œè·³è¿‡ã€‚")
                trade_initiated = False
        
        return trade_initiated

    def sync_outcomes(self):
        """
        [è‡ªåŠ¨å›å¡«] æ£€æŸ¥æ—§æ•°æ®å¹¶æ›´æ–° T+1h, T+24h çš„ä»·æ ¼
        é‡‡ç”¨ "Next Trading Candle" é€»è¾‘ï¼Œç¡®ä¿å¯¹é½äº¤æ˜“æ—¶æ®µã€‚
        """
        now = datetime.now(pytz.utc)
        # é¢‘ç‡æ§åˆ¶ï¼šå¦‚æœè·ç¦»ä¸Šæ¬¡å°è¯•ä¸è¶³å†·å´æ—¶é—´ï¼Œç›´æ¥è·³è¿‡
        if (now - self.last_sync_attempt).total_seconds() < self.sync_cooldown_minutes * 60:
            return

        pending_records = self.db.get_pending_outcomes()
        if not pending_records:
            return

        # é¢„è§£æå¹¶è¿‡æ»¤
        ready_records = []
        for record in pending_records:
            try:
                raw_time = record['timestamp']
                if isinstance(raw_time, str):
                    try:
                        dt = datetime.strptime(raw_time, "%Y-%m-%d %H:%M:%S")
                    except ValueError:
                        dt = datetime.strptime(raw_time, "%Y-%m-%d %H:%M:%S.%f%z")
                else:
                    dt = raw_time
                
                if dt.tzinfo is None:
                    dt = pytz.utc.localize(dt)
                else:
                    dt = dt.astimezone(pytz.utc)
                
                # åªå¤„ç† 15 åˆ†é’Ÿä»¥å‰çš„è®°å½•ï¼Œé¿å…é›…è™è¿˜æ²¡ç”Ÿæˆæœ€è¿‘çš„ Candle
                if (now - dt).total_seconds() > 900:
                    ready_records.append((record, dt))
            except:
                continue

        if not ready_records:
            return

        logger.info(f"â³ æ­£åœ¨åŒæ­¥ {len(ready_records)} æ¡å†å²æ•°æ®çš„æ”¶ç›Šç‡...")
        self.last_sync_attempt = now

        # 1. ç¡®å®šæ‰€éœ€çš„å†å²æ•°æ®èŒƒå›´
        min_time = min(r[1] for r in ready_records)
        max_time = max(r[1] for r in ready_records)

        # 2. è·å–å†å²æ•°æ® (ç¼“å†²ç¼©å°ä¸º 2 å¤©ä»¥å‡å°‘æ•°æ®é‡)
        fetch_start = (min_time - timedelta(days=2)).strftime('%Y-%m-%d')
        fetch_end = (max_time + timedelta(days=2)).strftime('%Y-%m-%d')
        
        logger.info(f"ğŸ“ˆ è·å–è¡Œæƒ…æ•°æ®èŒƒå›´: {fetch_start} è‡³ {fetch_end}")
        
        try:
            # Using Market Hub to get Gold Futures (GC) historical data
            # Note: Data source mainly provides daily data for foreign futures.
            # This is a domestic-friendly alternative.
            df = ak.futures_foreign_hist(symbol="GC")
            if df.empty:
                logger.warning("æœªèƒ½è·å–åˆ°è¡Œæƒ…æ•°æ®ï¼Œè·³è¿‡æœ¬æ¬¡åŒæ­¥")
                return

            # Format to match expectations: Index as UTC datetime, 'Close' column
            df['date'] = pd.to_datetime(df['date'])
            df = df.rename(columns={'close': 'Close', 'date': 'timestamp'})
            df = df.set_index('timestamp')
            
            if df.index.tz is None:
                df.index = df.index.tz_localize('UTC')
            else:
                df.index = df.index.tz_convert('UTC')
            
            hist = df[['Close']]
            
            # åŒæ­¥æˆåŠŸï¼Œæ¢å¤è¾ƒçŸ­çš„å†·å´æ—¶é—´
            self.sync_cooldown_minutes = 15
                
        except Exception as e:
            logger.warning(f"è·å–å†å²è¡Œæƒ…å¤±è´¥: {e}")
            return

        # 3. é€æ¡åŒ¹é… (Next Trading Candle)
        success_count = 0
        for record, record_time in ready_records:
            try:
                windows = {
                    'price_15m': timedelta(minutes=15),
                    'price_1h': timedelta(hours=1),
                    'price_4h': timedelta(hours=4),
                    'price_12h': timedelta(hours=12),
                    'price_24h': timedelta(hours=24)
                }
                
                outcomes = {}
                for col, delta in windows.items():
                    target_time = record_time + delta
                    idx = hist.index.searchsorted(target_time)
                    
                    if idx < len(hist):
                        matched_time = hist.index[idx]
                        if (matched_time - target_time).total_seconds() <= 4 * 86400:
                            outcomes[col] = round(float(hist.iloc[idx]['Close']), 2)

                if outcomes:
                    self.db.update_outcome(record['id'], **outcomes)
                    success_count += 1
                
            except Exception as e:
                logger.warning(f"å•æ¡å›å¡«å¤±è´¥ ID {record['id']}: {e}")
        
        logger.info(f"âœ… åŒæ­¥å®Œæˆ: æˆåŠŸå›å¡« {success_count}/{len(ready_records)} æ¡")

    def get_confidence_stats(self, keyword):
        """
        [ç­–ç•¥æ‰§è¡Œ] æ ¹æ®å…³é”®è¯æŸ¥è¯¢å†å²è¡¨ç°
        """
        try:
            with psycopg2.connect(
                host=settings.POSTGRES_HOST,
                port=settings.POSTGRES_PORT,
                user=settings.POSTGRES_USER,
                password=settings.POSTGRES_PASSWORD,
                dbname=settings.POSTGRES_DB
            ) as conn:
                with conn.cursor() as cursor:
                    query = """
                        SELECT gold_price_snapshot, price_1h 
                        FROM intelligence 
                        WHERE (content ILIKE %s OR summary::text ILIKE %s) 
                        AND price_1h IS NOT NULL
                    """
                    pattern = f"%{keyword}%"
                    cursor.execute(query, (pattern, pattern))
                    rows = cursor.fetchall()

            if not rows:
                return None

            total = len(rows)
            up_count = 0
            total_return = 0

            for start_price, end_price in rows:
                if not start_price or not end_price:
                    continue
                
                ret = (end_price - start_price) / start_price * 100
                total_return += ret
                if ret > 0:
                    up_count += 1
            
            if total == 0:
                return None

            return {
                "count": total,
                "win_rate": round(up_count / total * 100, 1),
                "avg_return": round(total_return / total, 2)
            }
        except Exception as e:
            logger.error(f"Error calculating confidence stats: {e}")
            return None